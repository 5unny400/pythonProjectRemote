# 爬虫

`robots.txt`：引导搜索引擎蜘蛛抓取指定栏目或内容;

eg: https://www.baidu.com/robots.txt

### 反爬

简单的情况下可通过`User-Agent`解决，简称UA

```
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36"
}
```

---

### 其它

#### 谷歌 `Preserve-log`

如果页面登录成功跳转过后看不到之前的请求数据，可以勾上`保留日志`
![img.png](images/Preserve-log.png)

#### 谷歌插件 `XPath Helper`

获取网页数据xpath

https://chrome.google.com/webstore/detail/xpath-helper/hgimnogjllphhhkhlmebbmlgjoejdpjl?hl=en

使用
![img.png](images/chrome-plugin-xpath.png)

#### 教学视频

| 已阅  | 来源                                                                                  |
|-----|-------------------------------------------------------------------------------------|
| √   | [尚硅谷Python爬虫教程小白零基础速通（含python基础+爬虫案例）](https://www.bilibili.com/video/BV1Db4y1m7Ho) |
